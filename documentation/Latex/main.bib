%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/


%% Created for Thomas Taylor at 2011-11-09 00:59:26 +0000 


%% Saved with string encoding Unicode (UTF-8) 



@proceedings{Gold:2005fk,
	Abstract = {Artificial intelligence research and video games are a natural match, and academia is a fertile place to blend game production and academic research. Game development tools and processes are valuable for applied AI research projects, and university departments can create opportunities for student-led, team-based project work that draws on students' interest in video games. The Digital Media Collaboratory at the University of Texas at Austin has developed a project in which academic AI research was incorporated into a video game production process that is repeatable in other universities. This process has yielded results that advance the field of machine learning as well as the state of the art in video games. This is a case study of the process and the project that originated it, outlining methods, results, and benefits in order to encourage the use of the model elsewhere.},
	Annote = {Summary:

Outlines a university-led AI project at University of Texas. NeuroEvolving Robotic Operatives (NERO) project looks at the evolution of neural networks with a genetic algorithm.

"In NERO, a player trains a group of ignorant robot soldiers by setting learning objectives for the group through an interface. After the objective is set, the robots learn in real time to achieve their goal"

NERO has a real-time training stage which is carried out before the actual game. Player can 'save' the team, and start the game, when learning is no longer taking place.


Other Notes:

- Documents the development process
- Used the Torque game engine (Garage Games)
- Use a 'spiral' method of development (design choices made iteratively)},
	Author = {Aliza Gold},
	Date-Added = {2011-11-09 00:59:22 +0000},
	Date-Modified = {2011-11-09 00:59:22 +0000},
	Journal = {IEEE - Symposium on Computational Intelligence and Games (CIG'05)},
	Pages = {8},
	Title = {Academic AI and Video games: a case study of incorporating innovative academic research into a video game prototype},
	Year = {2005},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUIJidUJHRvcFgkb2JqZWN0c1gkdmVyc2lvblkkYXJjaGl2ZXLRBgdUcm9vdIABqAkKFRYXGyIjVSRudWxs0wsMDQ4RFFpOUy5vYmplY3RzV05TLmtleXNWJGNsYXNzog8QgASABqISE4ACgAOAB1lhbGlhc0RhdGFccmVsYXRpdmVQYXRo0hgNGRpXTlMuZGF0YU8RAz4AAAAAAz4AAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAMpA9/xIKwAAAOl3GR9BY2FkZW1pYyBBSSBhbmQgVmlkZSNBRkE5MTEucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAr6kRytG7zgAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGMy1SZWFkABAACAAAykDp7AAAABEACAAAytGtvgAAAAEAGADpdxkAgLCQAFybmABJ7lgABQJ2AAC+7AACAHtNYWNpbnRvc2ggSEQ6VXNlcnM6AHRvbToAVW5pdmVyc2l0eToASW5kaXZpZHVhbCBQcm9qZWN0OgBNYWNoaW5lIGxlYXJuaW5nIHJlc2VhcmNoOgAzLVJlYWQ6AEFjYWRlbWljIEFJIGFuZCBWaWRlI0FGQTkxMS5wZGYAAA4A8gB4AEEAYwBhAGQAZQBtAGkAYwAgAEEASQAgAGEAbgBkACAAVgBpAGQAZQBvACAAZwBhAG0AZQBzAC0AIABhACAAYwBhAHMAZQAgAHMAdAB1AGQAeQAgAG8AZgAgAGkAbgBjAG8AcgBwAG8AcgBhAHQAaQBuAGcAIAAgAGkAbgBuAG8AdgBhAHQAaQB2AGUAIABhAGMAYQBkAGUAbQBpAGMAIAByAGUAcwBlAGEAcgBjAGgAIABpAG4AdABvACAAYQAgAHYAaQBkAGUAbwAgAGcAYQBtAGUAIABwAHIAbwB0AG8AdAB5AHAAZQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAwVVzZXJzL3RvbS9Vbml2ZXJzaXR5L0luZGl2aWR1YWwgUHJvamVjdC9NYWNoaW5lIGxlYXJuaW5nIHJlc2VhcmNoLzMtUmVhZC9BY2FkZW1pYyBBSSBhbmQgVmlkZW8gZ2FtZXMtIGEgY2FzZSBzdHVkeSBvZiBpbmNvcnBvcmF0aW5nICBpbm5vdmF0aXZlIGFjYWRlbWljIHJlc2VhcmNoIGludG8gYSB2aWRlbyBnYW1lIHByb3RvdHlwZS5wZGYAABMAAS8AABUAAgAK//8AAIAF0hwdHh9YJGNsYXNzZXNaJGNsYXNzbmFtZaMfICFdTlNNdXRhYmxlRGF0YVZOU0RhdGFYTlNPYmplY3RfEL0uLi8uLi9Vbml2ZXJzaXR5L0luZGl2aWR1YWwgUHJvamVjdC9NYWNoaW5lIGxlYXJuaW5nIHJlc2VhcmNoLzMtUmVhZC9BY2FkZW1pYyBBSSBhbmQgVmlkZW8gZ2FtZXMtIGEgY2FzZSBzdHVkeSBvZiBpbmNvcnBvcmF0aW5nICBpbm5vdmF0aXZlIGFjYWRlbWljIHJlc2VhcmNoIGludG8gYSB2aWRlbyBnYW1lIHByb3RvdHlwZS5wZGbSHB0kJaIlIVxOU0RpY3Rpb25hcnkSAAGGoF8QD05TS2V5ZWRBcmNoaXZlcgAIABEAFgAfACgAMgA1ADoAPABFAEsAUgBdAGUAbABvAHEAcwB2AHgAegB8AIYAkwCYAKAD4gPkA+kD8gP9BAEEDwQWBB8E3wTkBOcE9AT5AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAABQs=}}

@article{Auslander:2008kx,
	Abstract = {This paper presents CBRetaliate, an agent that combines Case-Based Reasoning (CBR) and Reinforcement Learning (RL) algorithms. Unlike most previous work where RL is used to improve accuracy in the action selection process, CBRetaliate uses CBR to allow RL to respond more quickly to changing conditions. CBRetaliate combines two key features: it uses a time window to compute similarity and stores and reuses complete Q-tables for continuous problem solving. We demon- strate CBRetaliate on a team-based first-person shooter game, where our combined CBR+RL approach adapts quicker to changing tactics by an opponent than standalone RL.},
	Annote = {Summary:

Research into using case-based reasoning to allow reinforcement learning to respond more quickly to to changing conditions. A definite focus on the implementation.

Gives a nice introduction to the use of reinforcement learning in games.

"In this paper we present CBRetaliate, an agent that uses Case-Based Reasoning (CBR) techniques to enhance the Retaliate RL agent. Unlike most previous work where RL is used to improve accuracy in the case selection process, CBRetaliate uses CBR to jump quickly to previously stored policies rather than slowly adapting to changing conditions"

If the system is doing 'well', it stores the current case for later reference.

Some nice, in-depth discussion of the algorithms used in the research, as well as the reasoning behind them - could be useful for designing my own algorithms later (also some pseudocode examples).},
	Author = {Bryan Auslander and Stephen Lee-Urban and Chad Hogg and Hector Munoz-Avila},
	Date-Added = {2011-11-09 00:54:50 +0000},
	Date-Modified = {2011-11-09 00:54:50 +0000},
	Journal = {ECCBR '08 Proceedings of the 9th European conference on Advances in Case-Based Reasoning},
	Pages = {15},
	Title = {Recognizing the Enemy: Combining Reinforcement Learning with Strategy Selection using Case-Based Reasoning},
	Year = {2008},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUIJidUJHRvcFgkb2JqZWN0c1gkdmVyc2lvblkkYXJjaGl2ZXLRBgdUcm9vdIABqAkKFRYXGyIjVSRudWxs0wsMDQ4RFFpOUy5vYmplY3RzV05TLmtleXNWJGNsYXNzog8QgASABqISE4ACgAOAB1lhbGlhc0RhdGFccmVsYXRpdmVQYXRo0hgNGRpXTlMuZGF0YU8RAyIAAAAAAyIAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAMpA9/xIKwAAAOl3GR9SZWNvZ25pemluZyB0aGUgZW5lbSNFQTk0RkQucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA6pT9ytxM5wAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGMy1SZWFkABAACAAAykDp7AAAABEACAAAytxM5wAAAAEAGADpdxkAgLCQAFybmABJ7lgABQJ2AAC+7AACAHtNYWNpbnRvc2ggSEQ6VXNlcnM6AHRvbToAVW5pdmVyc2l0eToASW5kaXZpZHVhbCBQcm9qZWN0OgBNYWNoaW5lIGxlYXJuaW5nIHJlc2VhcmNoOgAzLVJlYWQ6AFJlY29nbml6aW5nIHRoZSBlbmVtI0VBOTRGRC5wZGYAAA4A4ABvAFIAZQBjAG8AZwBuAGkAegBpAG4AZwAgAHQAaABlACAAZQBuAGUAbQB5ACAALQAgAEMAbwBtAGIAaQBuAGkAbgBnACAAcgBlAGkAbgBmAG8AcgBjAGUAbQBlAG4AdAAgAGwAZQBhAHIAbgBpAG4AZwAgAHcAaQB0AGgAIABzAHQAcgBhAHQAZQBnAHkAIABzAGUAbABlAGMAdABpAG8AbgAgAHUAcwBpAG4AZwAgAGMAYQBzAGUALQBiAGEAcwBlAGQAIAByAGUAYQBzAG8AbgBpAG4AZwAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAuFVzZXJzL3RvbS9Vbml2ZXJzaXR5L0luZGl2aWR1YWwgUHJvamVjdC9NYWNoaW5lIGxlYXJuaW5nIHJlc2VhcmNoLzMtUmVhZC9SZWNvZ25pemluZyB0aGUgZW5lbXkgLSBDb21iaW5pbmcgcmVpbmZvcmNlbWVudCBsZWFybmluZyB3aXRoIHN0cmF0ZWd5IHNlbGVjdGlvbiB1c2luZyBjYXNlLWJhc2VkIHJlYXNvbmluZy5wZGYAEwABLwAAFQACAAr//wAAgAXSHB0eH1gkY2xhc3Nlc1okY2xhc3NuYW1lox8gIV1OU011dGFibGVEYXRhVk5TRGF0YVhOU09iamVjdF8QtC4uLy4uL1VuaXZlcnNpdHkvSW5kaXZpZHVhbCBQcm9qZWN0L01hY2hpbmUgbGVhcm5pbmcgcmVzZWFyY2gvMy1SZWFkL1JlY29nbml6aW5nIHRoZSBlbmVteSAtIENvbWJpbmluZyByZWluZm9yY2VtZW50IGxlYXJuaW5nIHdpdGggc3RyYXRlZ3kgc2VsZWN0aW9uIHVzaW5nIGNhc2UtYmFzZWQgcmVhc29uaW5nLnBkZtIcHSQloiUhXE5TRGljdGlvbmFyeRIAAYagXxAPTlNLZXllZEFyY2hpdmVyAAgAEQAWAB8AKAAyADUAOgA8AEUASwBSAF0AZQBsAG8AcQBzAHYAeAB6AHwAhgCTAJgAoAPGA8gDzQPWA+ED5QPzA/oEAwS6BL8EwgTPBNQAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAAE5g==}}

@article{Miikkulainen:2006ys,
	Abstract = {Video games provide an ideal platform for the development and testing of machine-learning techniques.},
	Annote = {Summary:

Focuses on neuroevolution

Gives some examples of where machine learning has been used recently (early 00s)

Has a nice summary of research in the area including NEAT & NERO.

NeuroEvolution of Augmenting Topologies (NEAT) - evolving neural network appropriate for video games


Quotes:

"{\ldots}a large part of AI development is devoted to path-finding algorithms"

"a large part of the gameplay in many games is figuring out what the AI is programmed to do and learning to defeat it"

Evolutionary computation: "Each solution is evaluated in the task and assigned a fit- ness based on how well it performs. Individuals with high fitness are then reproduced (by crossing over their encodings) and mutated (by randomly changing components of their encodings with a low probability). The offspring of the high-fitness individu- als replace the low-fitness individuals in the popula- tion, and over time, solu- tions that can solve the task are discovered"

"Neuroevolution is particularly well suited to video games because (1) it works well in high-dimensional spaces; (2) diverse populations can be maintained; (3) individual networks behave consistently; (4) adaptation takes place in real time; and (5) memory can be implemented through recur- rency (Gomez et al., 2006; Stanley et al., 2005)"

"Entirely new game genres can be developed, such as machine-learning games, in which the player explicitly trains game agents to perform vari- ous tasks"

"To rtNEAT, [the sliders] represent coefficients for fitness components. For exam- ple, the sliders specify how much to reward or punish agents for approaching enemies, hitting targets, getting hit, following friends, dispersing, etc."},
	Author = {Risto Miikkulainen},
	Date-Added = {2011-11-09 00:38:29 +0000},
	Date-Modified = {2011-11-09 00:38:29 +0000},
	Pages = {9},
	Title = {Creating Intelligent Agents in Games},
	Volume = {Winter},
	Year = {2006},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUIJidUJHRvcFgkb2JqZWN0c1gkdmVyc2lvblkkYXJjaGl2ZXLRBgdUcm9vdIABqAkKFRYXGyIjVSRudWxs0wsMDQ4RFFpOUy5vYmplY3RzV05TLmtleXNWJGNsYXNzog8QgASABqISE4ACgAOAB1lhbGlhc0RhdGFccmVsYXRpdmVQYXRo0hgNGRpXTlMuZGF0YU8RAk4AAAAAAk4AAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAMpA9/xIKwAAAOl3GR9DcmVhdGluZyBJbnRlbGxpZ2VudCNFOTdDN0MucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA6Xx8ytthEwAAAAAAAAAAAAIABQAACSAAAAAAAAAAAAAAAAAAAAAGMy1SZWFkABAACAAAykDp7AAAABEACAAAytthEwAAAAEAGADpdxkAgLCQAFybmABJ7lgABQJ2AAC+7AACAHtNYWNpbnRvc2ggSEQ6VXNlcnM6AHRvbToAVW5pdmVyc2l0eToASW5kaXZpZHVhbCBQcm9qZWN0OgBNYWNoaW5lIGxlYXJuaW5nIHJlc2VhcmNoOgAzLVJlYWQ6AENyZWF0aW5nIEludGVsbGlnZW50I0U5N0M3Qy5wZGYAAA4AUgAoAEMAcgBlAGEAdABpAG4AZwAgAEkAbgB0AGUAbABsAGkAZwBlAG4AdAAgAEEAZwBlAG4AdABzACAAaQBuACAARwBhAG0AZQBzAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBxVXNlcnMvdG9tL1VuaXZlcnNpdHkvSW5kaXZpZHVhbCBQcm9qZWN0L01hY2hpbmUgbGVhcm5pbmcgcmVzZWFyY2gvMy1SZWFkL0NyZWF0aW5nIEludGVsbGlnZW50IEFnZW50cyBpbiBHYW1lcy5wZGYAABMAAS8AABUAAgAK//8AAIAF0hwdHh9YJGNsYXNzZXNaJGNsYXNzbmFtZaMfICFdTlNNdXRhYmxlRGF0YVZOU0RhdGFYTlNPYmplY3RfEG0uLi8uLi9Vbml2ZXJzaXR5L0luZGl2aWR1YWwgUHJvamVjdC9NYWNoaW5lIGxlYXJuaW5nIHJlc2VhcmNoLzMtUmVhZC9DcmVhdGluZyBJbnRlbGxpZ2VudCBBZ2VudHMgaW4gR2FtZXMucGRm0hwdJCWiJSFcTlNEaWN0aW9uYXJ5EgABhqBfEA9OU0tleWVkQXJjaGl2ZXIACAARABYAHwAoADIANQA6ADwARQBLAFIAXQBlAGwAbwBxAHMAdgB4AHoAfACGAJMAmACgAvIC9AL5AwIDDQMRAx8DJgMvA58DpAOnA7QDuQAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAPL}}

@article{Liden:2004fk,
	Author = {Lars Liden},
	Date-Added = {2011-11-09 00:34:30 +0000},
	Date-Modified = {2011-11-09 00:37:43 +0000},
	Journal = {AI Game Programming Wisdom},
	Number = {5},
	Pages = {8},
	Title = {Artificial Stupidity: The Art of Intentional Mistakes},
	Volume = {2},
	Year = {2004},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUIJidUJHRvcFgkb2JqZWN0c1gkdmVyc2lvblkkYXJjaGl2ZXLRBgdUcm9vdIABqAkKFRYXGyIjVSRudWxs0wsMDQ4RFFpOUy5vYmplY3RzV05TLmtleXNWJGNsYXNzog8QgASABqISE4ACgAOAB1lhbGlhc0RhdGFccmVsYXRpdmVQYXRo0hgNGRpXTlMuZGF0YU8RAoIAAAAAAoIAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAMpA9/xIKwAAAICwkB9BcnRpZmljaWFsIFN0dXBpZGl0eSNFQThEN0QucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA6o19ytxJuQAAAAAAAAAAAAIABAAACSAAAAAAAAAAAAAAAAAAAAAZTWFjaGluZSBsZWFybmluZyByZXNlYXJjaAAAEAAIAADKQOnsAAAAEQAIAADK3Em5AAAAAQAUAICwkABcm5gASe5YAAUCdgAAvuwAAgBzTWFjaW50b3NoIEhEOlVzZXJzOgB0b206AFVuaXZlcnNpdHk6AEluZGl2aWR1YWwgUHJvamVjdDoATWFjaGluZSBsZWFybmluZyByZXNlYXJjaDoAQXJ0aWZpY2lhbCBTdHVwaWRpdHkjRUE4RDdELnBkZgAADgB0ADkAQQByAHQAaQBmAGkAYwBpAGEAbAAgAFMAdAB1AHAAaQBkAGkAdAB5AC0AIABUAGgAZQAgAEEAcgB0ACAAbwBmACAASQBuAHQAZQBuAHQAaQBvAG4AYQBsACAATQBpAHMAdABhAGsAZQBzAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgB7VXNlcnMvdG9tL1VuaXZlcnNpdHkvSW5kaXZpZHVhbCBQcm9qZWN0L01hY2hpbmUgbGVhcm5pbmcgcmVzZWFyY2gvQXJ0aWZpY2lhbCBTdHVwaWRpdHktIFRoZSBBcnQgb2YgSW50ZW50aW9uYWwgTWlzdGFrZXMucGRmAAATAAEvAAAVAAIACv//AACABdIcHR4fWCRjbGFzc2VzWiRjbGFzc25hbWWjHyAhXU5TTXV0YWJsZURhdGFWTlNEYXRhWE5TT2JqZWN0XxB3Li4vLi4vVW5pdmVyc2l0eS9JbmRpdmlkdWFsIFByb2plY3QvTWFjaGluZSBsZWFybmluZyByZXNlYXJjaC9BcnRpZmljaWFsIFN0dXBpZGl0eS0gVGhlIEFydCBvZiBJbnRlbnRpb25hbCBNaXN0YWtlcy5wZGbSHB0kJaIlIVxOU0RpY3Rpb25hcnkSAAGGoF8QD05TS2V5ZWRBcmNoaXZlcgAIABEAFgAfACgAMgA1ADoAPABFAEsAUgBdAGUAbABvAHEAcwB2AHgAegB8AIYAkwCYAKADJgMoAy0DNgNBA0UDUwNaA2MD3QPiA+UD8gP3AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAABAk=}}

@webpage{mccarthy:2007fk,
	Annote = {Q. What is artificial intelligence?

A. It is the science and engineering of making intelligent machines, especially intelligent computer programs. It is related to the similar task of using computers to understand human intelligence, but AI does not have to confine itself to methods that are biologically observable.

Q. Yes, but what is intelligence?

A. Intelligence is the computational part of the ability to achieve goals in the world. Varying kinds and degrees of intelligence occur in people, many animals and some machines.

Q. Isn't there a solid definition of intelligence that doesn't depend on relating it to human intelligence?

A. Not yet. The problem is that we cannot yet characterize in general what kinds of computational procedures we want to call intelligent. We understand some of the mechanisms of intelligence and not others.

Q. Is intelligence a single thing so that one can ask a yes or no question ``Is this machine intelligent or not?''?

A. No. Intelligence involves mechanisms, and AI research has discovered how to make computers carry out some of them and not others. If doing a task requires only mechanisms that are well understood today, computer programs can give very impressive performances on these tasks. Such programs should be considered ``somewhat intelligent''.

Q. Isn't AI about simulating human intelligence?

A. Sometimes but not always or even usually. On the one hand, we can learn something about how to make machines solve problems by observing other people or just by observing our own methods. On the other hand, most work in AI involves studying the problems the world presents to intelligence rather than studying people or animals. AI researchers are free to use methods that are not observed in people or that involve much more computing than people can do.

Q. What about other comparisons between human and computer intelligence?

Arthur R. Jensen [Jen98], a leading researcher in human intelligence, suggests ``as a heuristic hypothesis'' that all normal humans have the same intellectual mechanisms and that differences in intelligence are related to ``quantitative biochemical and physiological conditions''. I see them as speed, short term memory, and the ability to form accurate and retrievable long term memories.

Whether or not Jensen is right about human intelligence, the situation in AI today is the reverse.

Computer programs have plenty of speed and memory but their abilities correspond to the intellectual mechanisms that program designers understand well enough to put in programs. Some abilities that children normally don't develop till they are teenagers may be in, and some abilities possessed by two year olds are still out. The matter is further complicated by the fact that the cognitive sciences still have not succeeded in determining exactly what the human abilities are. Very likely the organization of the intellectual mechanisms for AI can usefully be different from that in people.

Whenever people do better than computers on some task or computers use a lot of computation to do as well as people, this demonstrates that the program designers lack understanding of the intellectual mechanisms required to do the task efficiently.

Q. When did AI research start?

A. After WWII, a number of people independently started to work on intelligent machines. The English mathematician Alan Turing may have been the first. He gave a lecture on it in 1947. He also may have been the first to decide that AI was best researched by programming computers rather than by building machines. By the late 1950s, there were many researchers on AI, and most of them were basing their work on programming computers.

Q. What is the Turing test?

A. Alan Turing's 1950 article Computing Machinery and Intelligence [Tur50] discussed conditions for considering a machine to be intelligent. He argued that if the machine could successfully pretend to be human to a knowledgeable observer then you certainly should consider it intelligent. This test would satisfy most people but not all philosophers. The observer could interact with the machine and a human by teletype (to avoid requiring that the machine imitate the appearance or voice of the person), and the human would try to persuade the observer that it was human and the machine would try to fool the observer.

The Turing test is a one-sided test. A machine that passes the test should certainly be considered intelligent, but a machine could still be considered intelligent without knowing enough about humans to imitate a human.

Daniel Dennett's book Brainchildren [Den98] has an excellent discussion of the Turing test and the various partial Turing tests that have been implemented, i.e. with restrictions on the observer's knowledge of AI and the subject matter of questioning. It turns out that some people are easily led into believing that a rather dumb program is intelligent.

Q. Does AI aim at human-level intelligence?

A. Yes. The ultimate effort is to make computer programs that can solve problems and achieve goals in the world as well as humans. However, many people involved in particular research areas are much less ambitious.

Q. How far is AI from reaching human-level intelligence? When will it happen?

A. A few people think that human-level intelligence can be achieved by writing large numbers of programs of the kind people are now writing and assembling vast knowledge bases of facts in the languages now used for expressing knowledge.

However, most AI researchers believe that new fundamental ideas are required, and therefore it cannot be predicted when human-level intelligence will be achieved.

Many researchers invented non-computer machines, hoping that they would be intelligent in different ways than the computer programs could be. However, they usually simulate their invented machines on a computer and come to doubt that the new machine is worth building. Because many billions of dollars that have been spent in making computers faster and faster, another kind of machine would have to be very fast to perform better than a program on a computer simulating the machine.

Q. Are computers fast enough to be intelligent?

A. Some people think much faster computers are required as well as new ideas. My own opinion is that the computers of 30 years ago were fast enough if only we knew how to program them. Of course, quite apart from the ambitions of AI researchers, computers will keep getting faster.

Q. What about parallel machines?

A. Machines with many processors are much faster than single processors can be. Parallelism itself presents no advantages, and parallel machines are somewhat awkward to program. When extreme speed is required, it is necessary to face this awkwardness.

Q. What about making a ``child machine'' that could improve by reading and by learning from experience?

A. This idea has been proposed many times, starting in the 1940s. Eventually, it will be made to work. However, AI programs haven't yet reached the level of being able to learn much of what a child learns from physical experience. Nor do present programs understand language well enough to learn much by reading.

Q. What about chess?

A. Alexander Kronrod, a Russian AI researcher, said ``Chess is the Drosophila of AI.'' He was making an analogy with geneticists' use of that fruit fly to study inheritance. Playing chess requires certain intellectual mechanisms and not others. Chess programs now play at grandmaster level, but they do it with limited intellectual mechanisms compared to those used by a human chess player, substituting large amounts of computation for understanding. Once we understand these mechanisms better, we can build human-level chess programs that do far less computation than do present programs.

Unfortunately, the competitive and commercial aspects of making computers play chess have taken precedence over using chess as a scientific domain. It is as if the geneticists after 1910 had organized fruit fly races and concentrated their efforts on breeding fruit flies that could win these races.

Q. What about Go?

A. The Chinese and Japanese game of Go is also a board game in which the players take turns moving. Go exposes the weakness of our present understanding of the intellectual mechanisms involved in human game playing. Go programs are very bad players, in spite of considerable effort (not as much as for chess). The problem seems to be that a position in Go has to be divided mentally into a collection of subpositions which are first analyzed separately followed by an analysis of their interaction. Humans use this in chess also, but chess programs consider the position as a whole. Chess programs compensate for the lack of this intellectual mechanism by doing thousands or, in the case of Deep Blue, many millions of times as much computation.

Sooner or later, AI research will overcome this scandalous weakness.

Q. Don't some people say that AI is a bad idea?

A. The philosopher John Searle says that the idea of a non-biological machine being intelligent is incoherent. He proposes the Chinese room argument www-formal.stanford.edu/jmc/chinese.html The philosopher Hubert Dreyfus says that AI is impossible. The computer scientist Joseph Weizenbaum says the idea is obscene, anti-human and immoral. Various people have said that since artificial intelligence hasn't reached human level by now, it must be impossible. Still other people are disappointed that companies they invested in went bankrupt.

Q. Aren't computability theory and computational complexity the keys to AI? [Note to the layman and beginners in computer science: These are quite technical branches of mathematical logic and computer science, and the answer to the question has to be somewhat technical.]

A. No. These theories are relevant but don't address the fundamental problems of AI.

In the 1930s mathematical logicians, especially Kurt G{\"o}del and Alan Turing, established that there did not exist algorithms that were guaranteed to solve all problems in certain important mathematical domains. Whether a sentence of first order logic is a theorem is one example, and whether a polynomial equations in several variables has integer solutions is another. Humans solve problems in these domains all the time, and this has been offered as an argument (usually with some decorations) that computers are intrinsically incapable of doing what people do. Roger Penrose claims this. However, people can't guarantee to solve arbitrary problems in these domains either. See my Review of The Emperor's New Mind by Roger Penrose. More essays and reviews defending AI research are in [McC96a].

In the 1960s computer scientists, especially Steve Cook and Richard Karp developed the theory of NP-complete problem domains. Problems in these domains are solvable, but seem to take time exponential in the size of the problem. Which sentences of propositional calculus are satisfiable is a basic example of an NP-complete problem domain. Humans often solve problems in NP-complete domains in times much shorter than is guaranteed by the general algorithms, but can't solve them quickly in general.

What is important for AI is to have algorithms as capable as people at solving problems. The identification of subdomains for which good algorithms exist is important, but a lot of AI problem solvers are not associated with readily identified subdomains.

The theory of the difficulty of general classes of problems is called computational complexity. So far this theory hasn't interacted with AI as much as might have been hoped. Success in problem solving by humans and by AI programs seems to rely on properties of problems and problem solving methods that the neither the complexity researchers nor the AI community have been able to identify precisely.

Algorithmic complexity theory as developed by Solomonoff, Kolmogorov and Chaitin (independently of one another) is also relevant. It defines the complexity of a symbolic object as the length of the shortest program that will generate it. Proving that a candidate program is the shortest or close to the shortest is an unsolvable problem, but representing objects by short programs that generate them should sometimes be illuminating even when you can't prove that the program is the shortest.},
	Author = {John McCarthy},
	Date-Added = {2011-11-07 14:16:02 +0000},
	Date-Modified = {2011-11-07 14:20:35 +0000},
	Lastchecked = {2011-11-07},
	Month = {November},
	Title = {What Is Artificial Intelligence?},
	Url = {http://www-formal.stanford.edu/jmc/whatisai/node1.html},
	Year = {2007},
	Bdsk-Url-1 = {http://www-formal.stanford.edu/jmc/whatisai/node1.html}}
